{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights yolov7_230111.pt --conf 0.25 --img-size 1280 --source inference/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade setuptools pip --user\n",
    "#!pip install --ignore-installed PyYAML\n",
    "#!pip install Pillow\n",
    "\n",
    "!pip install onnx \n",
    "!pip install onnxruntime\n",
    "!pip install protobuf<4.21.3\n",
    "!pip install onnxruntime-gpu\n",
    "!pip install onnx>=1.9.0\n",
    "!pip install onnx-simplifier>=0.3.6 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python export.py --weights ./yolov7_230111.pt \\\n",
    "        --grid --end2end --simplify \\\n",
    "        --topk-all 20 --iou-thres 0.5 --conf-thres 0.35 \\\n",
    "        --img-size 640 640 --max-wh 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import time\n",
    "# import requests\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import onnxruntime as ort\n",
    "# from PIL import Image\n",
    "# from pathlib import Path\n",
    "# from collections import OrderedDict,namedtuple\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict,namedtuple\n",
    "\n",
    "\n",
    "cuda = True\n",
    "w = \"yolov7_230111.onnx\"\n",
    "\n",
    "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']\n",
    "print(providers)\n",
    "session = ort.InferenceSession(w, providers=providers)\n",
    "\n",
    "\n",
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, r, (dw, dh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_input(cv2_img, img_shape = (640, 640)):\n",
    "        names= [\n",
    "                'headline',\n",
    "                'doc',\n",
    "                'cir_stamp',\n",
    "                'rec_stamp'\n",
    "        ]\n",
    "\n",
    "        colors = {name:[random.randint(0, 255) for _ in range(3)] for i,name in enumerate(names)}\n",
    "\n",
    "        img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        image = img.copy()\n",
    "        image, ratio, dwdh = letterbox(image, new_shape=img_shape , auto=False)\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = np.expand_dims(image, 0)\n",
    "        image = np.ascontiguousarray(image)\n",
    "\n",
    "        im = image.astype(np.float32)\n",
    "        im /= 255\n",
    "        im.shape\n",
    "\n",
    "        outname = [i.name for i in session.get_outputs()]\n",
    "        outname\n",
    "\n",
    "        inname = [i.name for i in session.get_inputs()]\n",
    "        inname\n",
    "\n",
    "        inp = {inname[0]:im}\n",
    "        return inp, outname, [ratio, dwdh, names, colors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in: 4.538798809051514\n"
     ]
    }
   ],
   "source": [
    "cv2_img = cv2.imread(r'inference/images/0E31BE6F-D4B6-4678-BAC5-323F94679D96_vpQbc_1670227956485.jpg')\n",
    "# ONNX inference\n",
    "start_time = time.time()\n",
    "inp, outname, translate_params = translate_input(cv2_img)\n",
    "outputs = session.run(outname, inp)[0]\n",
    "print(\"done in:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detection(cv2_img, translate_params):\n",
    "    ratio, dwdh, names, colors = translate_params\n",
    "    ori_images = [cv2_img.copy()]\n",
    "    for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\n",
    "        image = ori_images[int(batch_id)]\n",
    "        box = np.array([x0,y0,x1,y1])\n",
    "        box -= np.array(dwdh*2)\n",
    "        box /= ratio\n",
    "        box = box.round().astype(np.int32).tolist()\n",
    "        cls_id = int(cls_id)\n",
    "        score = round(float(score),3)\n",
    "        name = names[cls_id]\n",
    "        color = colors[name]\n",
    "        name += ' '+str(score)\n",
    "        cv2.rectangle(image,box[:2],box[2:],color,2)\n",
    "        cv2.putText(image,name,(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,[225, 255, 255],thickness=2)  \n",
    "\n",
    "    return ori_images[0]\n",
    "    # Image.fromarray(ori_images[0])\n",
    "    # cv2.imwrite(\"output.jpg\", ori_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "list_img = glob.glob(\"D:/PPYData/image/*.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m      6\u001b[0m inp, outname, translate_params \u001b[39m=\u001b[39m translate_input(cv2_img)\n\u001b[1;32m----> 7\u001b[0m outputs \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mrun(outname, inp)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[39m# print(\"done in:\", time.time() - start_time)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[39m# print(outputs)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# batch_id,x0,y0,x1,y1,cls_id,score = outputs\u001b[39;00m\n\u001b[0;32m     12\u001b[0m include_cir_tamp \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(\u001b[39msum\u001b[39m([\u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mint\u001b[39m(each[\u001b[39m5\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m each \u001b[39min\u001b[39;00m outputs ]))\n",
      "File \u001b[1;32mc:\\Users\\luong\\anaconda3\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:200\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    198\u001b[0m     output_names \u001b[39m=\u001b[39m [output\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs_meta]\n\u001b[0;32m    199\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(output_names, input_feed, run_options)\n\u001b[0;32m    201\u001b[0m \u001b[39mexcept\u001b[39;00m C\u001b[39m.\u001b[39mEPFail \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    202\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, each in enumerate(list_img[600:800]):\n",
    "    fname = each.split(\"\\\\\")[-1]\n",
    "    cv2_img = cv2.imread(each)\n",
    "    # ONNX inference\n",
    "    start_time = time.time()\n",
    "    inp, outname, translate_params = translate_input(cv2_img)\n",
    "    outputs = session.run(outname, inp)[0]\n",
    "    # print(\"done in:\", time.time() - start_time)\n",
    "\n",
    "    # print(outputs)\n",
    "    # batch_id,x0,y0,x1,y1,cls_id,score = outputs\n",
    "    include_cir_tamp = bool(sum([True if int(each[5]) == 2 else False for each in outputs ]))\n",
    "    if include_cir_tamp == False:\n",
    "        vis_img = visualize_detection(cv2_img, translate_params)\n",
    "        # Image.fromarray(vis_img)\n",
    "        cv2.imwrite(f\"out_imgs/{fname}.jpg\", vis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "batch_id,x0,y0,x1,y1,cls_id,score = outputs[0]\n",
    "print(cls_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from inference import DocumentLayoutDetection\n",
    "\n",
    "documentLayoutDetection = DocumentLayoutDetection(\"yolov7_230111.onnx\", cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread(r\"inference\\images\\1BA61ED3-7520-4163-AAA6-68FA8FAFC900_3Knkm_1670161583401.jpg\")\n",
    "res, translate_params = documentLayoutDetection.run_infer(test_img)\n",
    "vis_img = documentLayoutDetection.visualize_detection(test_img, translate_params, res)\n",
    "cv2.imwrite(\"test.jpg\", vis_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc5644fd2b52d511b211cf140a1e1d228fa8006a12c8d99adabf32e3d6df441d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
